# DeepSeek 第四章代码验证

本仓库包含了DeepSeek第四章的代码示例，包括Transformer实现、混合专家模型(MoE)及其变种、模型压缩等技术。

## 实验验证环境

### 系统环境
- 操作系统: Windows 11 (10.0.26100)
- CPU: AMD Ryzen 9 7945HX 
- GPU: NVDIA GeForce RTX 4060 8G

### 软件环境
- Python: 3.9 (Conda环境: traffic)
- PyTorch: 1.10.1 (CUDA 11.8)
- NumPy: 2.0.2 (注意: 与PyTorch 1.10.1存在兼容性问题)
- Transformers: 4.52.4

### 验证结果
所有代码都已成功验证运行，但存在以下注意事项:
- NumPy 2.0.2与PyTorch 1.10.1存在兼容性警告
- 需要将PyTorch升级到2.1.0+才能使用transformers库中的预训练模型
- 对于依赖transformers库预训练模型的文件 (如4.3.1、4.3.3系列文件)，已经修改为使用自定义简化模型实现


### 版本兼容性建议
如果想使用原始代码中的预训练模型功能，建议:
```bash
pip install --upgrade torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## 环境设置

```bash
# 安装依赖
pip install -r requirements.txt
```

## 代码文件说明

### 4.1 Transformer实现

1. **transformer.py**
   - 通用Transformer架构的完整PyTorch实现
   - 包含MultiHeadAttention、PositionalEncoding、Encoder和Decoder等组件
   - 依赖: torch
   - 运行: `python transformer.py`

2. **4.1.1 transformer_implementation.py**
   - Transformer架构的PyTorch实现
   - 依赖: torch
   - 运行: `python "4.1.1 transformer_implementation.py"`

3. **4.1.3 Post-LN.py** 
   - Post-LN和Pre-LN架构的示例实现
   - 依赖: torch
   - 注意: 此文件为部分实现，可以使用transformer.py中的实现

### 4.2 混合专家模型(MoE)

1. **4.2.1 MoE.py**
   - 基础混合专家模型实现
   - 依赖: torch
   - 运行: `python "4.2.1 MoE.py"`

2. **4.2.2 Switch_Transformer.py**
   - Switch Transformer中Top-1路由器实现
   - 依赖: torch
   - 运行: `python "4.2.2 Switch_Transformer.py"`

3. **4.2.3 GShard Top-2.py**
   - GShard中Top-2路由器实现
   - 依赖: torch
   - 运行: `python "4.2.3 GShard Top-2.py"`

4. **4.2.4 DeepSeek_MoE.py**
   - DeepSeek-MoE分层路由器实现
   - 依赖: torch
   - 运行: `python "4.2.4 DeepSeek_MoE.py"`

### 4.3 模型优化与压缩

1. **4.3.1 Transformer_extension.py**
   - 不同规模Transformer模型的参数分析
   - 依赖: torch
   - 已修改: 使用自定义配置代替transformers库
   - 运行: `python "4.3.1 Transformer_extension.py"`

2. **4.3.2 DeepSpeed.py**
   - DeepSpeed加速框架使用示例
   - 依赖: torch, deepspeed, transformers
   - 运行: `python "4.3.2 DeepSpeed.py"`

3. **4.3.2 ONNX.py** (文件名已修正)
   - 模型导出至ONNX和TensorRT的示例
   - 依赖: torch, onnx, tensorrt, transformers
   - 运行: `python "4.3.2 ONNX.py"`

4. **4.3.3 Low-Rank Factorization.py**
   - 低秩分解(LoRA)实现
   - 依赖: torch
   - 已修改: 使用自定义模型代替transformers库
   - 运行: `python "4.3.3 Low-Rank Factorization.py"`

5. **4.3.3 Structured_Pruning.py**
   - 结构化剪枝示例
   - 依赖: torch
   - 已修改: 使用自定义模型代替transformers库
   - 运行: `python "4.3.3 Structured_Pruning.py"`

6. **4.3.3 Unstructured_Pruning.py**
   - 非结构化剪枝示例
   - 依赖: torch, transformers
   - 已修改: 使用自定义模型代替transformers库
   - 运行: `python "4.3.3 Unstructured_Pruning.py"`

## 模型自定义方案

由于环境兼容性和网络限制问题，添加了`model.py`文件提供以下功能：
- 自动检测环境是否满足要求
- 提供自定义模型作为预训练模型的替代方案
- 确保所有示例代码能够在各种环境下运行

示例代码会自动检测环境并选择合适的模型实现方式。

## 注意事项

- 部分代码为教学示例，可能需要额外数据或模型才能完整运行
- 运行TensorRT相关代码需要安装NVIDIA驱动和CUDA
- 如果遇到NumPy兼容性警告，可以尝试降级NumPy: `pip install numpy==1.23.5`
